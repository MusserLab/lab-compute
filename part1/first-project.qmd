# Your First R Project

In this chapter, you'll do a real single-cell RNA-seq analysis—from raw count data to a UMAP of cell clusters. Along the way, you'll learn how to use Positron's key features: the file explorer, console, environment pane, plots pane, and interactive code execution. By the end, you'll render the analysis into a shareable HTML report.

We'll work with a single-cell RNA-seq dataset from the freshwater sponge *Spongilla lacustris*, one of the organisms studied in the Musser Lab. The dataset contains about 10,000 cells across 4 samples. Don't worry about understanding every biological detail—focus on learning how Positron works and getting comfortable running R code interactively.

## Create a Project Folder

First, create a folder for this project and open it in Positron.

1. Open Positron
2. Go to **File → Open Folder**
3. Navigate to where you want to keep projects (e.g., `~/Documents`)
4. Click **New Folder**, name it `my-first-analysis`, then open it

Positron now treats this folder as your workspace. Everything you do—running code, browsing files, managing packages—happens relative to this folder.

Take a moment to look around the Positron interface:

- **File Explorer** (left sidebar): Shows files and folders in your project. Right now it's empty.
- **Console** (bottom panel): Where your R session will run. You may need to start one—click "Start R Session" in the status bar at the bottom if you don't see an R prompt.
- **Environment pane** (right panel, or bottom panel next to Console): Will show R objects as you create them. Look for the "Variables" tab.
- **Plots pane**: Will appear when you make your first plot.

[TODO: screenshot of Positron with empty project, panes labeled]

## Install Packages with renv

Before we can analyze data, we need to install some R packages. We'll use **renv** to manage packages for this project—renv gives each project its own package library, so installing or updating packages here won't affect your other projects.

In the R console, type (or paste) and press Enter:

```r
install.packages("renv")
renv::init()
```

Watch the console output—renv creates a project-specific library and a `renv.lock` file. **Look at the file explorer**: you should now see `renv/` and `renv.lock` appear.

The **lock file** (`renv.lock`) is a snapshot of every package installed in your project, including exact version numbers. This is what makes your analysis reproducible—a collaborator (or future you) can run `renv::restore()` on another machine to install the exact same package versions. You'll learn more about renv in the [renv chapter](../part2/renv.qmd).

Now install the packages we need. Since we initialized renv, `install.packages()` installs into the project-specific library rather than your system library:

```r
install.packages(c("Seurat", "leidenbase", "ggplot2", "patchwork", "dplyr", "here"))
```

This takes a few minutes—Seurat has many dependencies. The `leidenbase` package is needed for the Leiden clustering algorithm we'll use later. Watch the console output as packages download and compile. When it's done, save the state:

```r
renv::snapshot()
```

::: {.callout-note}
## renv::snapshot()
`renv::snapshot()` updates `renv.lock` with the exact versions of every package you've installed. Run it after installing new packages so the lock file stays current.
:::

## Get the Data and Analysis Script

We need two things: the *Spongilla* count matrix and the analysis script you'll run through.

### Download the data

Create a `data/` folder in your project:

- **In the file explorer**: Right-click in the empty space → **New Folder** → name it `data`
- **Or in the terminal** (toggle with Cmd+\` or Ctrl+\`): `mkdir data`

Now download the *Spongilla* count matrix. This is a single-cell dataset in 10X Genomics format—the same format you'll work with when analyzing your own data from the sequencing core. It contains about 10,000 cells across 4 samples and 40,000 genes.

[TODO: Add download link for Spongilla count matrix]

Place the downloaded folder inside `data/` so you have `data/spongilla_counts/` containing three files.

### Get the analysis script

Create a `scripts/` folder and an `outs/` folder the same way, then download the analysis script:

[TODO: Add download link for 01_seurat_basics.qmd]

Place it in `scripts/` so your project looks like:

```
my-first-analysis/
├── data/
│   └── spongilla_counts/
│       ├── barcodes.tsv.gz        # One barcode per cell
│       ├── features.tsv.gz        # One row per gene
│       └── matrix.mtx.gz          # The sparse count matrix
├── scripts/
│   └── 01_seurat_basics.qmd      # The analysis you'll run
├── outs/                          # Will hold script outputs
├── renv/
├── renv.lock
└── .Rprofile
```

**Look at the file explorer now.** You can click into folders to browse their contents. Click into `data/spongilla_counts/` to see the three files that make up a 10X count matrix.

[TODO: screenshot of file explorer showing project structure]

## Open the Analysis Script

Open `scripts/01_seurat_basics.qmd` by clicking on it in the file explorer.

This is a **Quarto document** (`.qmd`)—the format we use for analyses in the lab. If you've used RMarkdown before, Quarto is its successor: it has the same idea of mixing code and narrative, but with more features and equal support for both R and Python. When you render a `.qmd`, all the code runs and the results are woven into an HTML report.

Look at the structure of the file:

- **YAML header** (the block between `---` marks at the top): Metadata that tells Quarto how to render the document—title, author, output format, and execution options.
- **Markdown text**: Written explanation between code chunks. This is where you describe what the analysis does and why.
- **Code chunks** (blocks starting with `` ```{r} ``): R code that will be executed. Each chunk has a `#| label:` line that gives it a name.

We're going to run through this script **chunk by chunk**, interactively. This is how you'll develop analyses in the lab—running code, inspecting results, and iterating before rendering the final report.

::: {.callout-tip}
## Cmd+Enter: Your Most-Used Shortcut
**Cmd+Enter** (Ctrl+Enter on Windows) runs the current line or selection in the R console. **Cmd+Shift+Enter** runs the entire code chunk. You'll use these constantly during interactive development.
:::

## Step 1: Load Libraries

Find the first code chunk (labeled `setup`) and place your cursor inside it. Press **Cmd+Shift+Enter** to run the entire chunk.

```r
library(Seurat)
library(ggplot2)
library(patchwork)
library(dplyr)
library(here)
```

**Watch the console** at the bottom—you'll see library loading messages appear there. The code runs in the console, not in the document. This is **interactive execution**: you're exploring and developing, running code chunk by chunk, checking results as you go.

[TODO: screenshot of console showing library loading messages]

## Step 2: Load the Count Matrix

Run the next chunk (`load-data`). This loads the 10X count matrix and creates a Seurat object—the central data structure for single-cell analysis in R.

```r
counts <- Read10X(data.dir = here("data/spongilla_counts"))
sponge <- CreateSeuratObject(counts = counts, project = "spongilla")
sponge
```

Two things to notice:

1. **The console** prints a summary of the Seurat object: the number of genes (features) and cells (samples) in the dataset.
2. **The environment pane** (Variables tab) now shows two objects: `counts` (a sparse matrix) and `sponge` (a Seurat object). You can see the object type and size at a glance.

[TODO: screenshot of Environment pane showing counts and sponge objects]

Now let's inspect the cell metadata. Run this in the console:

```r
View(sponge@meta.data)
```

This opens Positron's **data viewer**—a spreadsheet-style view of the metadata, with one row per cell and columns like `orig.ident`, `nCount_RNA` (total UMIs per cell), and `nFeature_RNA` (genes detected per cell).

Notice two useful features of the data viewer:

- **Column histograms**: Each numeric column shows a small histogram at the top, giving you a quick summary of the distribution. You can immediately see the range and shape of `nCount_RNA` and `nFeature_RNA` without making a plot.
- **Filtering**: Click on a column header to filter rows. For example, you could filter `nFeature_RNA` to only show cells with more than 1,000 detected genes. This is useful for quickly exploring subsets of your data.

[TODO: screenshot of Data Viewer showing Seurat metadata with histograms visible]

## Step 3: Quality Control

Run the next chunk (`fig-qc-violin`). This creates violin plots of two key QC metrics, split by sample:

- **nCount_RNA** — total UMI counts per cell. Very low counts suggest empty droplets or dead cells.
- **nFeature_RNA** — number of genes detected per cell. Very low values suggest poor capture; very high values might indicate doublets (two cells in one droplet).

```r
VlnPlot(sponge, features = c("nFeature_RNA", "nCount_RNA"), ncol = 2,
        group.by = "orig.ident")
```

**Your first plot appears in the Plots pane!** The violin plots show the distribution of genes and UMI counts across all cells, split by sample. You can resize the Plots pane by dragging its border, and use the navigation arrows to flip between plots as you make more.

[TODO: screenshot of Plots pane showing VlnPlot split by sample]

::: {.callout-tip}
## Pop Out the Plots Pane
If you want a larger view of a plot, you can pop the Plots pane out into a separate window. Click the pop-out icon in the top-right corner of the Plots pane. This is especially useful for complex plots like UMAPs where you want to see fine detail.
:::

This dataset has already been quality-filtered, so the distributions should look clean—no extreme outliers. In a real analysis starting from unfiltered data, you would filter cells here based on these metrics.

::: {.callout-note}
## QC Filtering in Practice
With unfiltered data, you'd remove low-quality cells using `subset()`. For example, `subset(sponge, subset = nFeature_RNA > 200 & nFeature_RNA < 5000)` removes cells with too few or too many detected genes. The specific thresholds depend on your dataset—the violin plots help you choose reasonable cutoffs.
:::

## Step 4: Normalize and Find Variable Features

Run the `normalize` chunk. This does two things:

**Normalization** adjusts for differences in sequencing depth between cells. Some cells have more total UMIs than others, and this variation is mostly technical—not biological. `NormalizeData()` divides each cell's gene counts by the cell's total UMI count to get relative expression levels, then applies a log transformation. The log transformation addresses *heteroscedasticity*: without it, highly expressed genes would have much higher variance than lowly expressed genes, dominating downstream analyses. Log transformation helps equilibrate variance across genes with different expression levels.

**FindVariableFeatures** identifies the 2,000 genes whose expression varies most across cells. These are the genes that distinguish cell types and will drive the downstream analysis. Genes expressed at similar levels in every cell don't help us find structure in the data.

```r
sponge <- NormalizeData(sponge)
sponge <- FindVariableFeatures(sponge, selection.method = "vst", nfeatures = 2000)
```

Now run the `fig-variable-features` chunk to visualize the results:

```r
top10 <- head(VariableFeatures(sponge), 10)

plot1 <- VariableFeaturePlot(sponge)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)
plot2
```

A new plot appears in the **Plots pane** showing genes ranked by variability. The labeled points are the most variable genes. **Use the navigation arrows** in the Plots pane to flip between this plot and the earlier violin plot.

[TODO: screenshot of Plots pane showing variable feature plot]

## Step 5: Scale Data and Run PCA

Run the `scale-pca` chunk:

```r
sponge <- ScaleData(sponge)
sponge <- RunPCA(sponge)
```

**Scaling** shifts each gene to have mean 0 and variance 1. Together with the log normalization from the previous step, this ensures that both lowly and highly expressed genes contribute equally to the analysis. **PCA** (Principal Component Analysis) then reduces the data from thousands of genes down to a smaller number of dimensions (principal components) that capture the main axes of variation.

::: {.callout-note}
## A Note on Methods
Scaling followed by PCA is the standard Seurat workflow and a good default for most datasets. Other approaches exist—for example, SAM (Self-Assembling Manifolds) skips PCA entirely and can work well in some cases. As you gain experience, you may explore alternative methods, but the standard pipeline is where everyone starts.
:::

Now run the `fig-elbow` chunk to see the elbow plot:

```r
ElbowPlot(sponge, ndims = 50)
```

The elbow plot shows how much variation each PC explains. We need to choose how many PCs to use for clustering. Using too few PCs can cause you to miss real biological structure—clusters that should be separate may merge together. We'll use 40 PCs for this dataset; the curve has mostly flattened by then, meaning additional PCs add little new information.

[TODO: screenshot of Plots pane showing elbow plot]

## Step 6: Cluster Cells

Run the `cluster` chunk. This is the most computationally intensive step—it takes a moment.

```r
sponge <- FindNeighbors(sponge, dims = 1:40)
sponge <- FindClusters(sponge, resolution = 2, algorithm = 4)
sponge <- RunUMAP(sponge, dims = 1:40)
```

Three things happen here:

- **FindNeighbors** builds a graph connecting cells with similar expression profiles (using the first 40 PCs).
- **FindClusters** uses the Leiden algorithm to find communities of similar cells in that graph.
- **RunUMAP** projects the high-dimensional relationships into two dimensions for visualization.

When it finishes, **check the environment pane**—the `sponge` object now contains clustering results and UMAP coordinates. Run `View(sponge@meta.data)` again to see a new `seurat_clusters` column in the metadata.

::: {.callout-note}
## Clustering Parameters
- **dims = 1:40** — uses the first 40 PCs. Using too few PCs can cause you to miss real clusters in the data.
- **resolution = 2** — higher values produce more clusters. The right resolution depends on how many cell types you expect.
- **algorithm = 4** — Leiden algorithm, which generally produces more robust clusters than the default Louvain (algorithm = 1).
:::

## Step 7: The UMAP

Run the `fig-umap` chunk:

```r
DimPlot(sponge, reduction = "umap", label = TRUE) + NoLegend()
```

**This is the result you've been working toward**—a UMAP plot where each dot is a cell, colored by cluster. Cells that are close together have similar gene expression. Each cluster likely represents a distinct cell type or state.

[TODO: screenshot of UMAP DimPlot in Plots pane]

## Step 8: Gene Expression on the UMAP

Run the final chunk (`fig-features`):

```r
FeaturePlot(sponge, features = c("Eef1a1 A", "Pcna"))
```

This overlays gene expression onto the UMAP—each cell is colored by how strongly it expresses that gene. *Eef1a1* is an elongation factor that is a strong marker for archaeocytes (the stem cell-like cells of sponges), and *Pcna* is a proliferation marker (it marks cells that are actively dividing). Notice how expression is concentrated in specific clusters, not spread uniformly. In a real analysis, you'd plot known marker genes like these to identify which cluster corresponds to which cell type.

[TODO: screenshot of FeaturePlot in Plots pane]

## Render the Document

So far you've been running code **interactively**—chunk by chunk, with results appearing in the console, environment pane, and plots pane. This is how you develop and explore.

Now let's **render** the document. Rendering runs every code chunk in a **fresh R session** from top to bottom, and produces a polished HTML report. This is important because:

- It proves the analysis is **reproducible**—it runs start to finish without relying on objects you created interactively
- It catches **errors** you might miss during interactive development (like relying on a variable you defined in the console but forgot to include in the script)
- It produces a **shareable document** with all code, results, and narrative together

Open the terminal (Cmd+\` or Ctrl+\`) and run:

```bash
quarto render scripts/01_seurat_basics.qmd
mkdir -p outs/01_seurat_basics
mv scripts/01_seurat_basics.html outs/01_seurat_basics/
```

The first command renders the document—Quarto re-executes all your R code from scratch. Then we move the HTML output into the `outs/` folder, following the lab convention of keeping script outputs separate from source code. When it finishes, open `outs/01_seurat_basics/01_seurat_basics.html` in your browser to see the full analysis as a formatted report—code, plots, and your written explanations all together.

[TODO: screenshot of rendered HTML report in browser]

::: {.callout-tip}
## Interactive vs. Rendering
During development, **work interactively**—run chunks, inspect objects, iterate. When you're satisfied, **render** to confirm everything runs cleanly and to produce the final report. If rendering fails, the error messages tell you where the problem is.
:::

## What You've Learned

You've now used all of Positron's key features:

| Feature | What you used it for |
|---------|---------------------|
| **File Explorer** | Browsing project files, seeing data and output structure |
| **Console** | Running R code interactively, seeing output and messages |
| **Environment pane** | Inspecting R objects—their types, sizes, and contents |
| **Data Viewer** | Examining cell metadata with filtering and column histograms |
| **Plots pane** | Viewing violin plots, UMAP, and feature plots (with pop-out) |
| **Terminal** | Running `quarto render` to produce the HTML report |

And you've run a basic single-cell analysis pipeline:

1. **Loaded** a 10X count matrix into a Seurat object
2. **Inspected** QC metrics to check data quality across samples
3. **Normalized** and identified highly variable genes
4. **Scaled**, ran **PCA**, and chose dimensions with an elbow plot
5. **Clustered** cells with the Leiden algorithm
6. **Visualized** clusters on a UMAP and plotted gene expression

This is the starting point for every single-cell analysis in the lab. From here you'd identify cell types using marker genes, run differential expression, and explore biology—but the tools and workflow are exactly what you've just practiced.

## Try Claude Code

You installed Claude Code in the previous chapter. Now that you have a real project, try it out. Open the Claude Code panel in Positron's sidebar (or run `claude` in the terminal) and try a prompt like:

::: {.callout-warning title="Claude Code"}
Claude Code can read your project files and answer questions about your analysis in context.

> I just ran a Seurat analysis on Spongilla data and got clusters on a UMAP. Can you look at the script in `scripts/01_seurat_basics.qmd` and suggest some marker genes I could plot to start identifying cell types?

Claude will read your script, understand the analysis you've run, and suggest biologically relevant genes to explore—drawing on knowledge of sponge cell biology and single-cell analysis methods.
:::

Throughout this book, you'll see orange boxes like this one showing how Claude Code can help with each topic. Try the prompts as you encounter them—Claude Code works best when you give it specific context about what you're working on.

## What's Next

- **Part 2** dives deeper into each tool: the [Positron chapter](../part2/positron.qmd) covers more features and keyboard shortcuts, the [Quarto chapter](../part2/quarto.qmd) covers document syntax and options, and the [Project Organization chapter](../part2/project-organization.qmd) explains the lab's conventions for structuring projects.
- **The [Workflows](../part3/setup-walkthrough.qmd) section** shows how to set up a full lab project with Git, conda, proper folder structure, and GitHub—the production infrastructure you'll use for real analyses.
